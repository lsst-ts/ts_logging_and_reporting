{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters. Set defaults here.\n",
    "# Times Square replaces this cell with the user's parameters.\n",
    "record_limit = '99'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"imports\"></a>\n",
    "## Imports and General Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use packages available in the Rubin Science Platform\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pprint import pp\n",
    "from urllib.parse import urlencode\n",
    "from IPython.display import FileLink, display_markdown\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = 'usdf_dev'  # usdf-dev, tucson, slac, summit\n",
    "log_name = 'narrativelog'\n",
    "log = log_name\n",
    "limit = int(record_limit)\n",
    "response_timeout = 3.05  # seconds, how long to wait for connection\n",
    "read_timeout = 20  # seconds\n",
    "\n",
    "timeout = (float(response_timeout), float(read_timeout))\n",
    "\n",
    "summit = 'https://summit-lsp.lsst.codes'\n",
    "usdf = 'https://usdf-rsp-dev.slac.stanford.edu'\n",
    "tucson = 'https://tucson-teststand.lsst.codes'\n",
    "\n",
    "# Use server = tucson for dev testing\n",
    "server = os.environ.get('EXTERNAL_INSTANCE_URL', summit)\n",
    "\n",
    "service = f'{server}/{log}'\n",
    "service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"setup_source\"></a>\n",
    "## Setup Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Times Square, comment out next line and past next cell with contents of local python file.\n",
    "#! from lsst.ts.logging_and_reporting.source_adapters import NarrativelogAdapter\n",
    "# Once our logrep package has been installed in RSP, we can use the simpler \"import\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste contents of source_adapters.py here\n",
    "\n",
    "# This file is part of ts_logging_and_reporting.\n",
    "#\n",
    "# Developed for Vera C. Rubin Observatory Telescope and Site Systems.\n",
    "# This product includes software developed by the LSST Project\n",
    "# (https://www.lsst.org).\n",
    "# See the COPYRIGHT file at the top-level directory of this distribution\n",
    "# for details of code ownership.\n",
    "#\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\n",
    "\n",
    "############################################\n",
    "# Python Standard Library\n",
    "from urllib.parse import urlencode\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "############################################\n",
    "# External Packages\n",
    "import requests\n",
    "\n",
    "\n",
    "MAX_CONNECT_TIMEOUT = 3.1    # seconds\n",
    "MAX_READ_TIMEOUT = 90 * 60   # seconds\n",
    "\n",
    "class ApiAdapter:\n",
    "    def __init__(self, *,\n",
    "                 server_url='https://tucson-teststand.lsst.codes',\n",
    "                 connect_timeout=3.05,  # seconds\n",
    "                 read_timeout=10 * 60,  # seconds\n",
    "                 ):\n",
    "        self.server = server_url\n",
    "        self.c_timeout = min(MAX_CONNECT_TIMEOUT,\n",
    "                             float(connect_timeout))  # seconds\n",
    "        self.r_timeout = min(MAX_READ_TIMEOUT,  # seconds\n",
    "                             float(read_timeout))\n",
    "        self.timeout = (self.c_timeout, self.r_timeout)\n",
    "\n",
    "        # We may be accessing several endpoints of an API.\n",
    "        # If so, we will get different types of records for each.\n",
    "        # The following are for the \"primary_endpoint\".\n",
    "        self.ignore_fields = list()\n",
    "        self.categoricals = list()\n",
    "        self.foreign_keys = list()\n",
    "\n",
    "\n",
    "    def analytics(self, recs, categorical_fields=None):\n",
    "        non_cats = set([\n",
    "            'tags', 'urls', 'message_text', 'id', 'date_added',\n",
    "            'obs_id', 'day_obs', 'seq_num', 'parent_id', 'user_id',\n",
    "            'date_invalidated', 'date_begin', 'date_end',\n",
    "            'time_lost', # float\n",
    "            # 'systems','subsystems','cscs',  # values need special handling\n",
    "        ])\n",
    "        flds = set(recs[0].keys())\n",
    "        if not categorical_fields:\n",
    "            categorical_fields = flds\n",
    "        ignore_fields = flds - categorical_fields\n",
    "        facflds = flds - ignore_fields\n",
    "\n",
    "        # facets(field) = set(value-1, value-2, ...)\n",
    "        facets = {fld: set([str(r[fld])\n",
    "                    for r in recs if not isinstance(r[fld], list)])\n",
    "                    for fld in facflds}\n",
    "        return dict(fields=flds,\n",
    "                    facet_fields=facflds,\n",
    "                    facets=facets,\n",
    "                    )\n",
    "\n",
    "\n",
    "class NarrativelogAdapter(ApiAdapter):\n",
    "    service = 'narrativelog'\n",
    "    primary_endpoint = 'messages'\n",
    "    fields = {'category',\n",
    "              'components',\n",
    "              'cscs',\n",
    "              'date_added',\n",
    "              'date_begin',\n",
    "              'date_end',\n",
    "              'date_invalidated',\n",
    "              'id',\n",
    "              'is_human',\n",
    "              'is_valid',\n",
    "              'level',\n",
    "              'message_text',\n",
    "              'parent_id',\n",
    "              'primary_hardware_components',\n",
    "              'primary_software_components',\n",
    "              'site_id',\n",
    "              'subsystems',\n",
    "              'systems',\n",
    "              'tags',\n",
    "              'time_lost',\n",
    "              'time_lost_type',\n",
    "              'urls',\n",
    "              'user_agent',\n",
    "              'user_id'}\n",
    "    filters = {\n",
    "        'site_ids',\n",
    "        'message_text',  # Message text contain ...\n",
    "        'min_level',     # inclusive\n",
    "        'max_level',     # exclusive\n",
    "        'user_ids',\n",
    "        'user_agents',\n",
    "        'categories',\n",
    "        'exclude_categories',\n",
    "        'time_lost_types',\n",
    "        'exclude_time_lost_types',\n",
    "        'tags',          # at least one must be present.\n",
    "        'exclude_tags',  # all must be absent\n",
    "        'systems',\n",
    "        'exclude_systems',\n",
    "        'subsystems',\n",
    "        'exclude_subsystems',\n",
    "        'cscs',\n",
    "        'exclude_cscs',\n",
    "        'components',\n",
    "        'exclude_components',\n",
    "        'primary_software_components',\n",
    "        'exclude_primary_software_components',\n",
    "        'primary_hardware_components',\n",
    "        'exclude_primary_hardware_components',\n",
    "        'urls',\n",
    "        'min_time_lost',\n",
    "        'max_time_lost',\n",
    "        'has_date_begin',\n",
    "        'min_date_begin',\n",
    "        'max_date_begin',\n",
    "        'has_date_end',\n",
    "        'min_date_end',\n",
    "        'max_date_end',\n",
    "        'is_human',      # Allowed: either, true, false; Default=either\n",
    "        'is_valid',      # Allowed: either, true, false; Default=true\n",
    "        'min_date_added', # inclusive, TAI ISO string, no TZ\n",
    "        'max_date_added', # exclusive, TAI ISO string, no TZ\n",
    "        'has_date_invalidated',\n",
    "        'min_date_invalidated',\n",
    "        'max_date_invalidated',\n",
    "        'has_parent_id',\n",
    "        'order_by',\n",
    "        'offset',\n",
    "        'limit'\n",
    "    }\n",
    "\n",
    "    def get_messages(self,\n",
    "                     site_ids=None,\n",
    "                     message_text=None,\n",
    "                     min_date_end=None,\n",
    "                     max_date_end=None,\n",
    "                     is_human='either',\n",
    "                     is_valid='either',\n",
    "                     offset=None,\n",
    "                     limit=None\n",
    "                     ):\n",
    "        qparams = dict(is_human=is_human, is_valid=is_valid)\n",
    "        if site_ids:\n",
    "            qparams['site_ids'] = site_ids\n",
    "        if message_text:\n",
    "            qparams['message_text'] = message_text\n",
    "        if min_date_end:\n",
    "            qparams['min_date_end'] = min_date_end\n",
    "        if max_date_end:\n",
    "            qparams['max_date_end'] = max_date_end\n",
    "        if limit:\n",
    "            qparams['limit'] = limit\n",
    "\n",
    "        qstr = urlencode(qparams)\n",
    "        url = f'{self.server}/{self.service}/messages?{qstr}'\n",
    "        try:\n",
    "            recs = requests.get(url, timeout=self.timeout).json()\n",
    "        except Exception as err:\n",
    "            warnings.warn(f'No {self.service} records retrieved: {err}')\n",
    "            recs = []\n",
    "        if len(recs) == 0:\n",
    "            raise Exception(f'No records retrieved from {url}')\n",
    "\n",
    "        self.recs = recs\n",
    "        self.recs.sort(key=lambda r: r['date_begin'])\n",
    "        return recs\n",
    "\n",
    "    def get_timelost(self, rollup='day'):\n",
    "        day_tl = dict() # day_tl[day] = totalDayTimeLost\n",
    "        for day,dayrecs in itertools.groupby(\n",
    "                self.recs,\n",
    "                key=lambda r: datetime.fromisoformat(r['date_begin']).date().isoformat()\n",
    "                ):\n",
    "            day_tl[day] = sum([r['time_lost'] for r in dayrecs])\n",
    "        return day_tl\n",
    "\n",
    "class ExposurelogAdapter(ApiAdapter):\n",
    "    service = 'exposurelog'\n",
    "    primary_endpoint = 'messages'\n",
    "    fields = {'date_added',\n",
    "              'date_invalidated',\n",
    "              'day_obs',\n",
    "              'exposure_flag',\n",
    "              'id',\n",
    "              'instrument',\n",
    "              'is_human',\n",
    "              'is_valid',\n",
    "              'level',\n",
    "              'message_text',\n",
    "              'obs_id',\n",
    "              'parent_id',\n",
    "              'seq_num',\n",
    "              'site_id',\n",
    "              'tags',\n",
    "              'urls',\n",
    "              'user_agent',\n",
    "              'user_id'}\n",
    "    filters = {\n",
    "        'site_ids',\n",
    "        'obs_id',\n",
    "        'instruments',\n",
    "        'min_day_obs',  # inclusive, integer in form YYYMMDD\n",
    "        'max_day_obs',  # exclusive, integer in form YYYMMDD\n",
    "        'min_seq_num',\n",
    "        'max_seq_num',\n",
    "        'message_text',  # Message text contain ...\n",
    "        'min_level',     # inclusive\n",
    "        'max_level',     # exclusive\n",
    "        'tags',          # at least one must be present.\n",
    "        'urls',\n",
    "        'exclude_tags',  # all must be absent\n",
    "        'user_ids',\n",
    "        'user_agents',\n",
    "        'is_human',      # Allowed: either, true, false; Default=either\n",
    "        'is_valid',      # Allowed: either, true, false; Default=true\n",
    "        'exposure_flags',\n",
    "        'min_date_added', # inclusive, TAI ISO string, no TZ\n",
    "        'max_date_added', # exclusive, TAI ISO string, no TZ\n",
    "        'has_date_invalidated',\n",
    "        'min_date_invalidated',\n",
    "        'max_date_invalidated',\n",
    "        'has_parent_id',\n",
    "        'order_by',\n",
    "        'offset',\n",
    "        'limit'\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    def get_instruments(self):\n",
    "        url = f'{self.server}/{self.service}/instruments'\n",
    "        try:\n",
    "            instruments = requests.get(url, timeout=self.timeout).json()\n",
    "        except Exception as err:\n",
    "            warnings.warn(f'No instruments retrieved: {err}')\n",
    "            instruments = dict(dummy=[])\n",
    "        # Flatten the lists\n",
    "        return list(itertools.chain.from_iterable(instruments.values()))\n",
    "\n",
    "    def get_exposures(self, instrument, registry=1):\n",
    "        qparams = dict(instrument=instrument, registery=registry)\n",
    "        url = f'{self.server}/{self.service}/exposures?{urlencode(qparams)}'\n",
    "        try:\n",
    "            recs = requests.get(url, timeout=self.timeout).json()\n",
    "        except Exception as err:\n",
    "            warnings.warn(f'No exposures retrieved: {err}')\n",
    "            recs = []\n",
    "        return recs\n",
    "\n",
    "    def get_messages(self,\n",
    "                     site_ids=None,\n",
    "                     obs_ids=None,\n",
    "                     instruments=None,\n",
    "                     message_text=None,\n",
    "                     min_day_obs=None,\n",
    "                     max_day_obs=None,\n",
    "                     is_human='either',\n",
    "                     is_valid='either',\n",
    "                     exposure_flags=None,\n",
    "                     offset=None,\n",
    "                     limit=None\n",
    "                     ):\n",
    "        qparams = dict(is_human=is_human, is_valid=is_valid)\n",
    "        if site_ids:\n",
    "            qparams['site_ids'] = site_ids\n",
    "        if obs_ids:\n",
    "            qparams['obs_ids'] = obs_ids\n",
    "        if instruments:\n",
    "            qparams['instruments'] = instruments\n",
    "        if min_day_obs:\n",
    "            qparams['min_day_obs'] = min_day_obs\n",
    "        if max_day_obs:\n",
    "            qparams['max_day_obs'] = max_day_obs\n",
    "        if exposure_flags:\n",
    "            qparams['exposure_flags'] = exposure_flags\n",
    "        if offset:\n",
    "            qparams['offset'] = offset\n",
    "        if limit:\n",
    "            qparams['limit'] = limit\n",
    "\n",
    "        qstr = urlencode(qparams)\n",
    "        url = f'{self.server}/{self.service}/messages?{qstr}'\n",
    "        try:\n",
    "            recs = requests.get(url, timeout=self.timeout).json()\n",
    "        except Exception as err:\n",
    "            warnings.warn(f'No {self.service} records retrieved: {err}')\n",
    "            recs = []\n",
    "        if len(recs) == 0:\n",
    "            raise Exception(f'No records retrieved from {url}')\n",
    "\n",
    "        self.recs = recs\n",
    "        self.recs.sort(key=lambda r: r['day_obs'])\n",
    "        return recs\n",
    "\n",
    "    def get_observation_gaps(self, instruments=None,\n",
    "                             min_day_obs=None,  # YYYYMMDD\n",
    "                             max_day_obs=None,  # YYYYMMDD\n",
    "                             ):\n",
    "        if not instruments:\n",
    "            instruments = self.get_instruments()\n",
    "        assert isinstance(instruments,list), \\\n",
    "            f'\"instruments\" must be a list.  Got {instruments!r}'\n",
    "        # inst_day_rollupol[instrument] => dict[day] => exposureGapInMinutes\n",
    "        inst_day_rollup = defaultdict(dict)  # Instrument/Day rollup\n",
    "\n",
    "        for instrum in instruments:\n",
    "            recs = self.get_exposures(instrum)\n",
    "            instrum_gaps = dict()\n",
    "            for day,dayrecs in itertools.groupby(recs,\n",
    "                                                 key=lambda r: r['day_obs']):\n",
    "                gaps = list()\n",
    "                begin = end = None\n",
    "                for rec in dayrecs:\n",
    "                    begin = rec['timespan_begin']\n",
    "                    if end:\n",
    "                        # span in minutes\n",
    "                        diff = (datetime.fromisoformat(begin)\n",
    "                                - datetime.fromisoformat(end)\n",
    "                                ).total_seconds() / 60.0\n",
    "\n",
    "                        gaps.append((\n",
    "                            datetime.fromisoformat(end).time().isoformat(),\n",
    "                            datetime.fromisoformat(begin).time().isoformat(),\n",
    "                            diff\n",
    "                        ))\n",
    "                    end = rec['timespan_end']\n",
    "                instrum_gaps[day] = gaps\n",
    "\n",
    "                #!roll = dict()\n",
    "                # Rollup gap times by day\n",
    "                for day,tuples in instrum_gaps.items():\n",
    "                    #!roll[day] = sum([t[2] for t in tuples])\n",
    "                    inst_day_rollup[instrum][day] = sum([t[2] for t in tuples])\n",
    "\n",
    "        return inst_day_rollup\n",
    "\n",
    "\n",
    "\n",
    "# gaps,recs = logrep_utils.ExposurelogAdapter(server_url='https://usdf-rsp-dev.slac.stanford.edu').get_observation_gaps('LSSTComCam')\n",
    "\n",
    "# gaps,recs = logrep_utils.ExposurelogAdapter(server_url='[[https://tucson-teststand.lsst.codes').get_observation_gaps('LSSTComCam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"get_records\"></a>\n",
    "## Get Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_adapter = NarrativelogAdapter(server_url=server)\n",
    "try:\n",
    "    recs = service_adapter.get_messages()\n",
    "except Exception as err:\n",
    "    recs = []\n",
    "    msg = f'ERROR getting records from {server=}: {err=}'\n",
    "    raise Exception(msg)\n",
    "\n",
    "metrics = service_adapter.analytics(recs)\n",
    "flds = metrics['fields']\n",
    "facets = metrics['facets'] # facets(field) = set(value-1, value-2, ...)\n",
    "print(f'Retrieved {len(recs)} records, each with {len(flds)} fields.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_tl = service_adapter.get_timelost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"table\"></a>\n",
    "## Tables of (mostly raw) results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Fields names provided in records from log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(flds, columns=['Field Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Facets from log records.\n",
    "A *facet* is the set all of values found for a field in the retrieved records. Facets are only calculated for some fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame.from_dict(facets, orient='index'))\n",
    "facets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Show Retrieved Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_fields = ['id']\n",
    "new_column_names = dict(message_text='message',\n",
    "                        primary_software_components='PSC',\n",
    "                        primary_hardware_components='PHC',\n",
    "                       )\n",
    "\n",
    "df = pd.DataFrame(recs).rename(columns=new_column_names)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df.loc[:, ~df.columns.isin(ignore_fields)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Table of selected log record fields.\n",
    "Table can be retrieved as CSV file for local use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date_added', 'time_lost', 'time_lost_type']\n",
    "df = pd.DataFrame(recs)[cols]\n",
    "\n",
    "# Allow download of CSV version of DataFrame\n",
    "csvfile = 'tl.csv'\n",
    "df.to_csv(csvfile)\n",
    "myfile = FileLink(csvfile)\n",
    "print('Table available as CSV file: ')\n",
    "display(myfile)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['message_text','tags','user_id', 'components','date_end']\n",
    "df = pd.DataFrame(recs, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"plot\"></a>\n",
    "## Plots from log (per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_markdown(f'### Date vs Time Lost', raw=True)\n",
    "x = date_tl.keys()\n",
    "y = date_tl.values()\n",
    "\n",
    "df = pd.DataFrame(dict(day=x,time_lost=y))\n",
    "df.plot.bar(x='day', y='time_lost', title=f'Time Lost')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"raw_analysis\"></a>\n",
    "## Raw Content Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Example of one record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = recs[-1]\n",
    "\n",
    "msg = rec[\"message_text\"]\n",
    "md = f'Message text from log:\\n> {msg}'\n",
    "display_markdown(md, raw=True)\n",
    "\n",
    "md = f'One full record (the last one retrieved):\\n> {rec}'\n",
    "display_markdown(md, raw=True)\n",
    "\n",
    "display(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"elicitation\"></a>\n",
    "## Stakeholder Elicitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Finished run: {str(datetime.now())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
