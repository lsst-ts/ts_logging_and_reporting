{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters. \n",
    "# Times Square replaces this cell with the user's parameters.\n",
    "\n",
    "# The run-time defaults for all of these parameters are in NightLog.yaml\n",
    "# Under Times Square, the run-time defaults always override values given here.\n",
    "# Values here are used for local tests.\n",
    "\n",
    "# day_obs values: TODAY, YESTERDAY, YYYY-MM-DD\n",
    "# Report on observing nights that start upto but not included this day.\n",
    "day_obs = '2024-09-04' # Value to use for local testing (Summit)\n",
    "#!day_obs = 'TODAY' # TODO Change to 'TODAY' to test with default before push  \n",
    "\n",
    "# Total number of days of data to display (ending on day_obs)\n",
    "number_of_days = '12'  # TODO Change to '1' to test with default before push  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use packages available in the Rubin Science Platform\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pprint import pp\n",
    "from urllib.parse import urlencode\n",
    "from IPython.display import display, Markdown, display_markdown\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import datetime, date, timedelta\n",
    "#! from rubin_scheduler.site_models import Almanac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Parameters (both explicit Times Squares params, in implicit ones)\n",
    "limit = 50  # YAGNI: Auto get more if this isn't enough to get all requested DAYS\n",
    "\n",
    "match day_obs.lower():\n",
    "    case 'today':\n",
    "        date = datetime.now().date()\n",
    "    case 'yesterday':\n",
    "        date = datetime.now().date()-timedelta(days=1)\n",
    "    case _:\n",
    "        date = datetime.strptime(day_obs, '%Y-%m-%d').date()\n",
    "# date:  is EXLUSIVE (upto, but not including)\n",
    "days = int(number_of_days)\n",
    "\n",
    "# Thus: [min_day_obs,max_day_obs)\n",
    "min_day_obs = (date - timedelta(days=days-1)).strftime('%Y%m%d') # Inclusive\n",
    "max_day_obs = (date + timedelta(days=1)).strftime('%Y%m%d') # prep for Exclusive\n",
    "\n",
    "response_timeout = 3.05  # seconds, how long to wait for connection\n",
    "read_timeout = 20  # seconds\n",
    "timeout = (float(response_timeout), float(read_timeout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default env to \"usdf\" and try before PUSH to repo.\n",
    "summit = 'https://summit-lsp.lsst.codes'\n",
    "usdf = 'https://usdf-rsp-dev.slac.stanford.edu'\n",
    "tucson = 'https://tucson-teststand.lsst.codes'\n",
    "\n",
    "# The default provided here is for local testing.\n",
    "# Under Times Square it is ignored.\n",
    "server = os.environ.get('EXTERNAL_INSTANCE_URL', summit) # TODO try with \"usdf\" before push (else \"summit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running under Times Square, install pkg from github.\n",
    "# Otherwise use what is installed locally (intended to be dev editiable pkg)\n",
    "if os.environ.get('EXTERNAL_INSTANCE_URL'):\n",
    "    print('Installing \"lsst.ts.logging_and_reporting\" from github using \"prototype\" branch....')\n",
    "    !pip install --upgrade git+https://github.com/lsst-ts/ts_logging_and_reporting.git@prototype >/dev/null\n",
    "import lsst.ts.logging_and_reporting.source_adapters as sad\n",
    "import lsst.ts.logging_and_reporting.almanac as alm\n",
    "from lsst.ts.logging_and_reporting.reports import md,mdlist,dict_to_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lsst.ts.logging_and_reporting.version\n",
    "    lrversion = lsst.ts.logging_and_reporting.version.__version__\n",
    "except:\n",
    "    lrversion = 'LIVE'\n",
    "\n",
    "try:\n",
    "    from lsst_efd_client import EfdClient\n",
    "    enable_efd = True\n",
    "except:\n",
    "    enable_efd = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(f'''\n",
    "Report for **{date}** covering the previous **{days}** observing night(s).\n",
    "- Run on logs from **{server}/**\n",
    "- Using *Prototype* Logging and Reporting Version: **{lrversion}**\n",
    "- {enable_efd=}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "# Almanac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = alm.Almanac()\n",
    "pd.DataFrame(a.as_dict).T   # TODO get rid of bogus header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Nightly Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_adapter = sad.NightReportAdapter(server_url=server)\n",
    "nr_url = nr_adapter.source_url\n",
    "try:\n",
    "    nr_recs,nr_url = nr_adapter.get_reports(\n",
    "                                        limit=limit,\n",
    "                                        min_day_obs=min_day_obs,\n",
    "                                        max_day_obs=max_day_obs,\n",
    "                                        )\n",
    "except Exception as err:\n",
    "    nr_recs = []\n",
    "    msg = f'ERROR getting records from {nr_url=}: {err=}'\n",
    "    raise Exception(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Retrieved {len(nr_recs)} records from {nr_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "front = 'https://rubinobs.atlassian.net/projects/BLOCK?selectedItem=com.atlassian.plugins.atlassian-connect-plugin:com.kanoah.test-manager__main-project-page#!/'\n",
    "tickets = nr_adapter.nightly_tickets(nr_recs)\n",
    "\n",
    "if tickets:\n",
    "    mdstr = '## Nightly Jira BLOCKs'\n",
    "    for day, url_list in tickets.items():\n",
    "        mdstr += f'\\n- {day}'\n",
    "        for ticket_url in url_list:\n",
    "            mdstr += f'\\n    - [{ticket_url.replace(front,\"\")}]({ticket_url})'\n",
    "    md(mdstr)\n",
    "else:\n",
    "    md(f'No jira BLOCK tickets found.', color='lightblue')\n",
    "    md(f'Used: [API Data]({nr_url})')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Exposure Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_adapter = sad.ExposurelogAdapter(server_url=server)\n",
    "exposure_url = exposure_adapter.source_url\n",
    "try:\n",
    "    exposure_recs,url = exposure_adapter.get_messages(\n",
    "                                        limit=limit,\n",
    "                                        min_day_obs=min_day_obs,\n",
    "                                        max_day_obs=max_day_obs,\n",
    "                                        )\n",
    "except Exception as err:\n",
    "    exposure_recs = []\n",
    "    msg = f'ERROR getting records from {url=}: {err=}'\n",
    "    raise Exception(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exposure_recs:\n",
    "    table = exposure_adapter.day_table(exposure_recs,'date_added', dayobs_field='day_obs')\n",
    "    #print(table)\n",
    "    mdlist(table)\n",
    "else:\n",
    "    md(f'No Exposure Log records found.', color='lightblue')\n",
    "    md(f'Used [API Data]({exposure_url})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if usdf == os.environ.get('EXTERNAL_INSTANCE_URL'):\n",
    "    md(f\"**Warning:** The `/exposures/` endpoint is not yet functional on SERVER=usdf.\", color='red')\n",
    "gaps = exposure_adapter.get_observation_gaps(min_day_obs=min_day_obs,\n",
    "                                             max_day_obs=max_day_obs\n",
    "                                            )\n",
    "if gaps:\n",
    "    md(f'### Date vs Observation Gap (minutes) for all Instruments')\n",
    "    for instrument, day_gaps in gaps.items():\n",
    "        if len(day_gaps) == 0:\n",
    "            md(f'**No day gaps found for *{instrument=!s}* **', color='lightblue')\n",
    "        else:\n",
    "            x,y = zip(*day_gaps.items())\n",
    "            df = pd.DataFrame(dict(day=x,minutes=y))\n",
    "            df.plot.bar(x='day', y='minutes', title=f'{instrument=!s}')\n",
    "else:\n",
    "    md(f'No Observation Gaps found in exposures.', color='lightblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Narrative Log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrative_adapter = sad.NarrativelogAdapter(server_url=server)\n",
    "narrative_url = narrative_adapter.source_url\n",
    "try:\n",
    "    # date like '2000-01-02 12:00:00'\n",
    "    # str(datetime(2000, 1, 2, 12, 0, 0))\n",
    "    min_date = str(datetime.strptime(min_day_obs,'%Y%m%d'))\n",
    "    max_date = str(datetime.strptime(max_day_obs,'%Y%m%d'))\n",
    "    print(f'Get data from {narrative_url}: {min_date} to {max_date}')\n",
    "    narrative_recs,url = narrative_adapter.get_messages(\n",
    "        limit=limit,\n",
    "        min_date_end=min_date,\n",
    "        max_date_end=max_date\n",
    "    )\n",
    "except Exception as err:\n",
    "    narrative_recs = []\n",
    "    msg = f'ERROR getting records from {url}: {err=}'\n",
    "    raise Exception(msg)\n",
    "\n",
    "print(f'Retrieved {len(narrative_recs)} records.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if narrative_recs:\n",
    "    table = narrative_adapter.day_table(narrative_recs, 'date_added')\n",
    "    #print(tabstr)\n",
    "    #mdlist(table, color=\"darkblue\")\n",
    "    mdlist(table)\n",
    "else:\n",
    "    md(f'No Narrative Log records found.', color='lightblue')\n",
    "    md(f'Used [API Data]({narrative_url})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get('EXTERNAL_INSTANCE_URL'):\n",
    "    %run ./dashboard.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
